{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2-Pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaapivalli/Machine-Learning/blob/main/GPT2_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4L7HpNaFHO5D",
        "outputId": "207f0509-cbbc-4cc7-a1a9-4dc4c1457c12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/graykode/gpt-2-Pytorch\n",
        "%cd gpt-2-Pytorch\n",
        "!curl --output gpt2-pytorch_model.bin https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpt-2-Pytorch'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 130 (delta 29), reused 25 (delta 25), pack-reused 94 (from 1)\u001b[K\n",
            "Receiving objects: 100% (130/130), 2.39 MiB | 5.72 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/gpt-2-Pytorch\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  522M  100  522M    0     0  13.2M      0  0:00:39  0:00:39 --:--:-- 13.9M\n",
            "Collecting regex==2017.4.5 (from -r requirements.txt (line 1))\n",
            "  Downloading regex-2017.04.05.tar.gz (601 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.6/601.6 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp311-cp311-linux_x86_64.whl size=667359 sha256=8db84a9bf99618025b68ad8a268dca7a522364effa3eef730b1bbfdf33c1ab74\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/a6/66/e3a6bac658db8ce49c1537c63759ec8f81150b8bbe3b39deb4\n",
            "Successfully built regex\n",
            "Installing collected packages: regex\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nltk 3.9.1 requires regex>=2021.8.3, but you have regex 2017.4.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed regex-2017.4.5\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "he_YiEC9T6-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c49fa6f-7b41-47bb-c9a2-40eee8150e5f"
      },
      "cell_type": "code",
      "source": [
        "!python main.py --text \"Once when I was six years old I saw a magnificent picture in a book, called True Stories from Nature, about the primeval forest.\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-2-Pytorch/main.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('gpt2-pytorch_model.bin', map_location='cpu' if not torch.cuda.is_available() else None)\n",
            "Namespace(text='Once when I was six years old I saw a magnificent picture in a book, called True Stories from Nature, about the primeval forest.', quiet=False, nsamples=1, unconditional=False, batch_size=-1, length=-1, temperature=0.7, top_k=40)\n",
            "Once when I was six years old I saw a magnificent picture in a book, called True Stories from Nature, about the primeval forest.\n",
            "100% 512/512 [00:07<00:00, 68.06it/s]\n",
            "======================================== SAMPLE 1 ========================================\n",
            " There was a beautiful picture of a large rock called the Great Ganges, the most beautiful place in the world. I saw that picture in the book, and I was very happy.\n",
            "\n",
            "But then I was in my twenties when I saw something that really surprised me. The name of the mountain was called the Great Ganges, and it was called the Great Ganges Lake. This was a beautiful mountain, and it was about a kilometer to the north of the lake. It was called the Great Ganges Lake. It was very big, and it was very beautiful. It was a beautiful lake, and it was very cool. And I was very happy that it was called the Great Ganges Lake.\n",
            "\n",
            "And when I was forty-five or fifty I went to the Great Ganges National Park. And I was standing in the middle of the Great Ganges and there was a huge rock called the Great Ganges Lake. And I was very happy. I was walking along the Great Ganges Lake. And I saw a few people who were in the middle of it, and I was very happy, because they were very happy. And I was very happy.\n",
            "\n",
            "And I thought that I must have been a beautiful kid because I had seen that picture, and I was very happy. I thought that I must have been a little bit of a kid because I was very happy.\n",
            "\n",
            "And then when I was twenty-six or thirty I got a letter from the American Academy of Pediatrics. And the doctor said that the Great Ganges Lake had a very high potential for disease, and she said, \"Well, what can we do about it?\"\n",
            "\n",
            "And I said, \"Well, that's a great question. It's a very important question, because if you have a problem with the water that's flowing through that lake, you can get an infection. And you can get an infection if you have a really big problem with the water that's flowing through the water. And there's just no way to control that. And if you do, the water will become worse, and that's not a good thing.\n",
            "\n",
            "And I was very glad that the doctor said, \"Well, we're going to have to stop the water flowing through that lake. We are going to have to stop the water flowing through that lake. We are going to have to stop the water flowing through that lake. And what we're going to do is we are going to look for a solution. And I'm going\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTbC6W7i7ojW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}